{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a20fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns #For visulisation\n",
    "import matplotlib.pyplot as plt #For visulisation\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "pd.set_option('display.max_columns', 100) #replace n with the number of columns you want to see completely\n",
    "pd.set_option('display.max_rows', 100) #replace n with the number of rows you want to see completely\n",
    "\n",
    "# Read the data\n",
    "train_data_original = pd.read_csv('./Data/train.csv')\n",
    "metadata= pd.read_csv('./Data/greeks.csv')\n",
    "test_data=pd.read_csv('./Data/test.csv')\n",
    "sample_submission=pd.read_csv('./Data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b1c5ea93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "8353ee1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolating Ids and creating train_data\n",
    "train_data = train_data_original.copy()\n",
    "ids= train_data.pop('Id')\n",
    "y=train_data.pop('Class')\n",
    "\n",
    "#Ordinal encoding\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "train_data=enc.fit_transform(train_data)\n",
    "\n",
    "#Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=0.33, random_state=42)\n",
    "\n",
    "#Impute\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train=imp_mean.fit_transform(X_train)\n",
    "X_test=imp_mean.fit_transform(X_test);\n",
    "\n",
    "#Oversample\n",
    "X_train_resampled, y_train_resampled = SMOTE().fit_resample(X_train, y_train)\n",
    "\n",
    "#Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_resampled_scaled = scaler.fit_transform(X_train_resampled)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "features=train_data_original.columns.drop(['Id','Class'])\n",
    "X_train_resampled_scaled_df=pd.DataFrame(columns=features, data=X_train_resampled_scaled)\n",
    "X_test_scaled_df = pd.DataFrame(columns=features, data=X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "59b3b430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "def balanced_log_loss(y_true, y_pred):\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes = np.unique(y_true), y = y_true)\n",
    "    weights = class_weights[y_true.astype(int)]\n",
    "    loss = log_loss(y_true, y_pred, sample_weight=weights)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a83113d",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ab70639e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_model_XGB=XGBClassifier(max_depth=7, eta=0.4,tree_method='exact',scale_pos_weight=scaleposweight)\n",
    "baseline_model_XGB.fit(X_train_resampled,y_train_resampled)\n",
    "baseline_XGB_predictions=baseline_model_XGB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c798ec8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.93      0.95       161\n",
      "           1       0.78      0.88      0.83        43\n",
      "\n",
      "    accuracy                           0.92       204\n",
      "   macro avg       0.87      0.91      0.89       204\n",
      "weighted avg       0.93      0.92      0.92       204\n",
      "\n",
      "[[150  11]\n",
      " [  5  38]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, baseline_XGB_predictions, labels=[0,1]))\n",
    "print(confusion_matrix(y_test,baseline_XGB_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc848557",
   "metadata": {},
   "source": [
    "### W/ class weighting&Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a80aeb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "weights = class_weight.compute_sample_weight('balanced', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6d8fd58f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    6.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "#Impute\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X=imp_mean.fit_transform(train_data)\n",
    "\n",
    "scaleposweight= 509/108\n",
    "\n",
    "XGB_cross_val=XGBClassifier(max_depth=7, eta=0.4)\n",
    "cross_val = cross_validate(XGB_cross_val, \n",
    "                           X, y, \n",
    "                           cv=10, \n",
    "                           verbose=1,\n",
    "                           n_jobs=-1, \n",
    "                           return_estimator=True, \n",
    "                           return_train_score=True,\n",
    "                           scoring=['balanced_accuracy','f1_weighted']\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "b70e4363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.81818182, 0.84402852, 0.81818182, 0.86987522, 0.94474153,\n",
       "       0.85383244, 0.8083779 , 0.79818182, 0.89019608, 0.85      ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val['test_balanced_accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d59a1efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: Balanced accuracy=0.818 , weighted f1=0.93\n",
      "---------------------------------------------------\n",
      "Fold 2: Balanced accuracy=0.844 , weighted f1=0.918\n",
      "---------------------------------------------------\n",
      "Fold 3: Balanced accuracy=0.818 , weighted f1=0.93\n",
      "---------------------------------------------------\n",
      "Fold 4: Balanced accuracy=0.87 , weighted f1=0.906\n",
      "---------------------------------------------------\n",
      "Fold 5: Balanced accuracy=0.945 , weighted f1=0.968\n",
      "---------------------------------------------------\n",
      "Fold 6: Balanced accuracy=0.854 , weighted f1=0.933\n",
      "---------------------------------------------------\n",
      "Fold 7: Balanced accuracy=0.808 , weighted f1=0.914\n",
      "---------------------------------------------------\n",
      "Fold 8: Balanced accuracy=0.798 , weighted f1=0.898\n",
      "---------------------------------------------------\n",
      "Fold 9: Balanced accuracy=0.89 , weighted f1=0.95\n",
      "---------------------------------------------------\n",
      "Fold 10: Balanced accuracy=0.85 , weighted f1=0.947\n",
      "---------------------------------------------------\n",
      "Average balanced acc:  0.85\n",
      "Average weighted f1:  0.929\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print('Fold %s: Balanced accuracy=%s , weighted f1=%s' % (i+1, round(cross_val['test_balanced_accuracy'][i],3) ,\n",
    "                                                             round(cross_val['test_f1_weighted'][i],3)))\n",
    "    print('---------------------------------------------------')\n",
    "print('Average balanced acc: ',round(cross_val['test_balanced_accuracy'].mean(),3))\n",
    "print('Average weighted f1: ',round(cross_val['test_f1_weighted'].mean(),3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17aed5c3",
   "metadata": {},
   "source": [
    "### With gridsearch param optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "62b8dc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:378: FitFailedWarning: \n",
      "400 fits failed out of a total of 2400.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:45] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:46] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:47] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:48] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:49] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:50] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:51] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "26 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:52] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:53] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "24 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:54] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:55] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "28 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:56] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:57] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "29 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:58] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "23 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:33:59] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "25 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:34:00] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1516, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "  File \"C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 279, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: [23:34:01] c:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-03de431ba26204c4d-1\\xgboost\\xgboost-ci-windows\\src\\data\\iterative_dmatrix.h:90: Not implemented.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Nicolas\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.84331263 0.84331263        nan 0.84331263 0.84331263        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.87349896 0.87349896        nan 0.87349896 0.87349896        nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.8879089  0.8879089         nan 0.8879089  0.8879089         nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89792961 0.89792961        nan 0.89792961 0.89792961        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.89652174 0.89652174        nan 0.89652174 0.89652174        nan\n",
      " 0.92664596 0.93099379 0.92809524 0.91805383 0.91656315 0.91801242\n",
      " 0.90078675 0.89650104 0.89648033 0.876294   0.87917184 0.8763147\n",
      " 0.92811594 0.93097308 0.92095238 0.92376812 0.92086957 0.92376812\n",
      " 0.90219462 0.90223602 0.89795031 0.8763354  0.8820911  0.87919255\n",
      " 0.9310352  0.93389234 0.93674948 0.92376812 0.91942029 0.9194617\n",
      " 0.90223602 0.90225673 0.89937888 0.8763354  0.8820911  0.87919255\n",
      " 0.92387164 0.92674948 0.93530021 0.92231884 0.92086957 0.92091097\n",
      " 0.90223602 0.90225673 0.89937888 0.8763354  0.8820911  0.87919255\n",
      " 0.9410559  0.93674948 0.94250518 0.93242236 0.93389234 0.92956522\n",
      " 0.91803313 0.92089027 0.91950311 0.90219462 0.90076605 0.90648033\n",
      " 0.93674948 0.93962733 0.93964803 0.92954451 0.93391304 0.93387164\n",
      " 0.91950311 0.91801242 0.9194824  0.90360248 0.90076605 0.90362319\n",
      " 0.94111801 0.94109731 0.94111801 0.93097308 0.93244306 0.93679089\n",
      " 0.92238095 0.92378882 0.92238095 0.90360248 0.90076605 0.90362319\n",
      " 0.93966874 0.94254658 0.93964803 0.92954451 0.9310352  0.93672878\n",
      " 0.92238095 0.91950311 0.92238095 0.90360248 0.90076605 0.90362319\n",
      " 0.93821946 0.94540373 0.94538302 0.93958592 0.93240166 0.93819876\n",
      " 0.92380952 0.9252588  0.92664596 0.91227743 0.90801242 0.91660455\n",
      " 0.94109731 0.94538302 0.94538302 0.9410766  0.93962733 0.93817805\n",
      " 0.92378882 0.92813665 0.9252795  0.91231884 0.91086957 0.91374741\n",
      " 0.94395445 0.94681159 0.94254658 0.94109731 0.93391304 0.93672878\n",
      " 0.92668737 0.92666667 0.92815735 0.91231884 0.91086957 0.91374741\n",
      " 0.94828157 0.94391304 0.94971014 0.93672878 0.93387164 0.93966874\n",
      " 0.92380952 0.9252381  0.92815735 0.91231884 0.91086957 0.91374741\n",
      " 0.94252588 0.95115942 0.946853   0.93530021 0.92819876 0.94256729\n",
      " 0.92956522 0.92238095 0.92380952 0.9194824  0.91662526 0.91084886\n",
      " 0.94403727 0.94830228 0.946853   0.93824017 0.9410766  0.93538302\n",
      " 0.93246377 0.9310352  0.92242236 0.91082816 0.91227743 0.91374741\n",
      " 0.94538302 0.94828157 0.9468323  0.93819876 0.94536232 0.93677019\n",
      " 0.92960663 0.92960663 0.92674948 0.91082816 0.91227743 0.91374741\n",
      " 0.94540373 0.94111801 0.94538302 0.9410766  0.93679089 0.93391304\n",
      " 0.92960663 0.92960663 0.92674948 0.91082816 0.91227743 0.91374741\n",
      " 0.94971014 0.94968944 0.94250518 0.93824017 0.94109731 0.93821946\n",
      " 0.93248447 0.9252588  0.92093168 0.91082816 0.91803313 0.91374741\n",
      " 0.94971014 0.94679089 0.94828157 0.93824017 0.94397516 0.93966874\n",
      " 0.93536232 0.9252795  0.92666667 0.90944099 0.91229814 0.91519669\n",
      " 0.94540373 0.9468323  0.94254658 0.93824017 0.94544513 0.93968944\n",
      " 0.93248447 0.92813665 0.9194824  0.90944099 0.91229814 0.91519669\n",
      " 0.94544513 0.95113872 0.94828157 0.94113872 0.93830228 0.93966874\n",
      " 0.93248447 0.92670807 0.9194824  0.90944099 0.91229814 0.91519669]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_b...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;booster&#x27;: [&#x27;gblinear&#x27;, &#x27;gbtree&#x27;],\n",
       "                         &#x27;eta&#x27;: [0.05, 0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7],\n",
       "                         &#x27;min_child_weight&#x27;: [1, 10, 20, 30],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;exact&#x27;, &#x27;approx&#x27;, &#x27;hist&#x27;]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_b...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={&#x27;booster&#x27;: [&#x27;gblinear&#x27;, &#x27;gbtree&#x27;],\n",
       "                         &#x27;eta&#x27;: [0.05, 0.1, 0.2, 0.3, 0.4],\n",
       "                         &#x27;max_depth&#x27;: [4, 5, 6, 7],\n",
       "                         &#x27;min_child_weight&#x27;: [1, 10, 20, 30],\n",
       "                         &#x27;tree_method&#x27;: [&#x27;exact&#x27;, &#x27;approx&#x27;, &#x27;hist&#x27;]},\n",
       "             scoring=&#x27;balanced_accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     callbacks=None, colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None,\n",
       "                                     early_stopping_rounds=None,\n",
       "                                     enable_categorical=False, eval_metric=None,\n",
       "                                     feature_types=None, gamma=None,\n",
       "                                     gpu_id=None, grow_policy=None,\n",
       "                                     importance_type=None,\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_b...\n",
       "                                     max_leaves=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None,\n",
       "                                     num_parallel_tree=None, predictor=None,\n",
       "                                     random_state=None, ...),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'booster': ['gblinear', 'gbtree'],\n",
       "                         'eta': [0.05, 0.1, 0.2, 0.3, 0.4],\n",
       "                         'max_depth': [4, 5, 6, 7],\n",
       "                         'min_child_weight': [1, 10, 20, 30],\n",
       "                         'tree_method': ['exact', 'approx', 'hist']},\n",
       "             scoring='balanced_accuracy')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {\n",
    "    'eta':[0.05,0.1,0.2,0.3,0.4],\n",
    "    'max_depth':[4,5,6,7],\n",
    "    'tree_method':['exact','approx','hist'],\n",
    "    'booster':['gblinear','gbtree'],\n",
    "    'min_child_weight':[1,10,20,30]\n",
    "}\n",
    "\n",
    "XGB_model= XGBClassifier()\n",
    "clf = GridSearchCV(XGB_model,\n",
    "                   parameters,\n",
    "                   scoring='balanced_accuracy',\n",
    "                   n_jobs=-1)\n",
    "clf.fit(X_train_resampled,y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95bc66ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'booster': 'gbtree', 'eta': 0.3, 'max_depth': 4, 'min_child_weight': 1, 'tree_method': 'approx'}\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', callbacks=None,\n",
      "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
      "              early_stopping_rounds=None, enable_categorical=False, eta=0.3,\n",
      "              eval_metric=None, feature_types=None, gamma=0, gpu_id=-1,\n",
      "              grow_policy='depthwise', importance_type=None,\n",
      "              interaction_constraints='', learning_rate=0.300000012,\n",
      "              max_bin=256, max_cat_threshold=64, max_cat_to_onehot=4,\n",
      "              max_delta_step=0, max_depth=4, max_leaves=0, min_child_weight=1,\n",
      "              missing=nan, monotone_constraints='()', n_estimators=100,\n",
      "              n_jobs=0, num_parallel_tree=1, predictor='auto', ...)\n",
      "0.951159420289855\n",
      "make_scorer(balanced_accuracy_score)\n"
     ]
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_estimator_)\n",
    "print(clf.best_score_)\n",
    "print(clf.scorer_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "085d2f26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       161\n",
      "           1       0.91      0.93      0.92        43\n",
      "\n",
      "    accuracy                           0.97       204\n",
      "   macro avg       0.95      0.95      0.95       204\n",
      "weighted avg       0.97      0.97      0.97       204\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_XGB_model= XGBClassifier(eta=0.3,\n",
    "                             max_depth=4,\n",
    "                             min_child_weight=1,\n",
    "                             tree_method='approx',\n",
    "                            booster='gbtree'\n",
    "                             )\n",
    "best_XGB_model.fit(X_train_resampled,y_train_resampled)\n",
    "best_predictions=best_XGB_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, best_predictions, labels=[0,1]))\n",
    "print(confusion_matrix(y_test,best_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5868be16",
   "metadata": {},
   "source": [
    "### Selecting features based on importance with RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "90aaa1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting estimator with 56 features.\n",
      "Fitting estimator with 55 features.\n",
      "Fitting estimator with 54 features.\n",
      "Fitting estimator with 53 features.\n",
      "Fitting estimator with 52 features.\n",
      "Fitting estimator with 51 features.\n",
      "Fitting estimator with 50 features.\n",
      "Fitting estimator with 49 features.\n",
      "Fitting estimator with 48 features.\n",
      "Fitting estimator with 47 features.\n",
      "Fitting estimator with 46 features.\n",
      "Fitting estimator with 45 features.\n",
      "Fitting estimator with 44 features.\n",
      "Fitting estimator with 43 features.\n",
      "Fitting estimator with 42 features.\n",
      "Fitting estimator with 41 features.\n",
      "Fitting estimator with 40 features.\n",
      "Fitting estimator with 39 features.\n",
      "Fitting estimator with 38 features.\n",
      "Fitting estimator with 37 features.\n",
      "Fitting estimator with 36 features.\n",
      "Fitting estimator with 35 features.\n",
      "Fitting estimator with 34 features.\n",
      "Fitting estimator with 33 features.\n",
      "Fitting estimator with 32 features.\n",
      "Fitting estimator with 31 features.\n",
      "Fitting estimator with 30 features.\n",
      "Fitting estimator with 29 features.\n",
      "Fitting estimator with 28 features.\n",
      "Fitting estimator with 27 features.\n",
      "Fitting estimator with 26 features.\n",
      "Fitting estimator with 25 features.\n",
      "Fitting estimator with 24 features.\n",
      "Fitting estimator with 23 features.\n",
      "Fitting estimator with 22 features.\n",
      "Fitting estimator with 21 features.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                            colsample_bylevel=None, colsample_bynode=None,\n",
       "                            colsample_bytree=None, early_stopping_rounds=None,\n",
       "                            enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "                            feature_types=None, gamma=None, gpu_id=None,\n",
       "                            grow_policy=None, importance_type=None,\n",
       "                            interaction_constraints=None, learning_rate=None,\n",
       "                            max_bin=None, max_cat_threshold=None,\n",
       "                            max_cat_to_onehot=None, max_delta_step=None,\n",
       "                            max_depth=4, max_leaves=None, min_child_weight=1,\n",
       "                            missing=nan, monotone_constraints=None,\n",
       "                            n_estimators=100, n_jobs=None,\n",
       "                            num_parallel_tree=None, predictor=None, ...),\n",
       "    n_features_to_select=20, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "                            colsample_bylevel=None, colsample_bynode=None,\n",
       "                            colsample_bytree=None, early_stopping_rounds=None,\n",
       "                            enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "                            feature_types=None, gamma=None, gpu_id=None,\n",
       "                            grow_policy=None, importance_type=None,\n",
       "                            interaction_constraints=None, learning_rate=None,\n",
       "                            max_bin=None, max_cat_threshold=None,\n",
       "                            max_cat_to_onehot=None, max_delta_step=None,\n",
       "                            max_depth=4, max_leaves=None, min_child_weight=1,\n",
       "                            missing=nan, monotone_constraints=None,\n",
       "                            n_estimators=100, n_jobs=None,\n",
       "                            num_parallel_tree=None, predictor=None, ...),\n",
       "    n_features_to_select=20, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, ...)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "              feature_types=None, gamma=None, gpu_id=None, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=4,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, predictor=None, ...)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=XGBClassifier(base_score=None, booster='gbtree', callbacks=None,\n",
       "                            colsample_bylevel=None, colsample_bynode=None,\n",
       "                            colsample_bytree=None, early_stopping_rounds=None,\n",
       "                            enable_categorical=False, eta=0.3, eval_metric=None,\n",
       "                            feature_types=None, gamma=None, gpu_id=None,\n",
       "                            grow_policy=None, importance_type=None,\n",
       "                            interaction_constraints=None, learning_rate=None,\n",
       "                            max_bin=None, max_cat_threshold=None,\n",
       "                            max_cat_to_onehot=None, max_delta_step=None,\n",
       "                            max_depth=4, max_leaves=None, min_child_weight=1,\n",
       "                            missing=nan, monotone_constraints=None,\n",
       "                            n_estimators=100, n_jobs=None,\n",
       "                            num_parallel_tree=None, predictor=None, ...),\n",
       "    n_features_to_select=20, verbose=1)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "XGB_classifier_RFE=XGBClassifier(eta=0.3,\n",
    "                             max_depth=4,\n",
    "                             min_child_weight=1,\n",
    "                             tree_method='approx',\n",
    "                            booster='gbtree'\n",
    "                             )\n",
    "rfe = RFE(estimator=XGB_classifier_RFE, n_features_to_select=20, step=1, verbose=1)\n",
    "rfe.fit(X_train_resampled_scaled_df, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9d926cd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False False False False  True False  True False False False\n",
      "  True False  True False False  True  True False False  True False False\n",
      "  True  True False False False False False False  True  True  True False\n",
      "  True False False False  True  True False False False False False False\n",
      "  True False False  True False False False  True]\n"
     ]
    }
   ],
   "source": [
    "print(rfe.support_)\n",
    "best_features=np.where(rfe.support_)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b2a76f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_df = pd.DataFrame(columns=features, data=X_test)\n",
    "X_train_best_features=X_train_resampled_scaled_df.iloc[:, best_features]\n",
    "X_test_best_features=X_test_df.iloc[:, best_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "022b2332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.32      0.46       161\n",
      "           1       0.24      0.81      0.37        43\n",
      "\n",
      "    accuracy                           0.42       204\n",
      "   macro avg       0.55      0.57      0.42       204\n",
      "weighted avg       0.73      0.42      0.44       204\n",
      "\n",
      "[[ 51 110]\n",
      " [  8  35]]\n"
     ]
    }
   ],
   "source": [
    "XGB_Classifier=XGBClassifier(eta=0.3,\n",
    "                             max_depth=4,\n",
    "                             min_child_weight=1,\n",
    "                             tree_method='approx',\n",
    "                            booster='gbtree'\n",
    "                             )\n",
    "XGB_Classifier.fit(X_train_best_features,y_train_resampled)\n",
    "predictions=XGB_Classifier.predict(X_test_best_features)\n",
    "\n",
    "print(classification_report(y_test, predictions, labels=[0,1]))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f122666e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10622627, 0.02264898, 0.06031855, 0.13106522, 0.0434755 ,\n",
       "       0.03708456, 0.03080915, 0.03758005, 0.05917044, 0.02934432,\n",
       "       0.03059536, 0.14414527, 0.02991094, 0.03429962, 0.02447634,\n",
       "       0.06047499, 0.0300967 , 0.03671928, 0.02707693, 0.02448163],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Classifier.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db56b396",
   "metadata": {},
   "source": [
    "### Selecting features based on importance with SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0c0ee154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresh=0.000, n=56, Accuracy: 97.28%\n",
      "Thresh=0.000, n=56, Accuracy: 97.28%\n",
      "Thresh=0.000, n=54, Accuracy: 97.28%\n",
      "Thresh=0.001, n=53, Accuracy: 97.28%\n",
      "Thresh=0.002, n=52, Accuracy: 95.27%\n",
      "Thresh=0.002, n=51, Accuracy: 96.12%\n",
      "Thresh=0.002, n=50, Accuracy: 96.43%\n",
      "Thresh=0.003, n=49, Accuracy: 94.34%\n",
      "Thresh=0.003, n=48, Accuracy: 90.62%\n",
      "Thresh=0.004, n=47, Accuracy: 90.93%\n",
      "Thresh=0.005, n=46, Accuracy: 90.93%\n",
      "Thresh=0.005, n=45, Accuracy: 90.31%\n",
      "Thresh=0.006, n=44, Accuracy: 90.00%\n",
      "Thresh=0.006, n=43, Accuracy: 90.00%\n",
      "Thresh=0.006, n=42, Accuracy: 90.85%\n",
      "Thresh=0.007, n=41, Accuracy: 90.00%\n",
      "Thresh=0.007, n=40, Accuracy: 91.78%\n",
      "Thresh=0.007, n=39, Accuracy: 92.32%\n",
      "Thresh=0.007, n=38, Accuracy: 92.32%\n",
      "Thresh=0.008, n=37, Accuracy: 90.62%\n",
      "Thresh=0.008, n=36, Accuracy: 88.52%\n",
      "Thresh=0.009, n=35, Accuracy: 87.90%\n",
      "Thresh=0.009, n=34, Accuracy: 91.70%\n",
      "Thresh=0.009, n=33, Accuracy: 93.72%\n",
      "Thresh=0.010, n=32, Accuracy: 93.17%\n",
      "Thresh=0.011, n=31, Accuracy: 90.23%\n",
      "Thresh=0.012, n=30, Accuracy: 89.30%\n",
      "Thresh=0.013, n=29, Accuracy: 91.08%\n",
      "Thresh=0.013, n=28, Accuracy: 90.54%\n",
      "Thresh=0.015, n=27, Accuracy: 90.46%\n",
      "Thresh=0.016, n=26, Accuracy: 89.30%\n",
      "Thresh=0.016, n=25, Accuracy: 89.84%\n",
      "Thresh=0.017, n=24, Accuracy: 88.36%\n",
      "Thresh=0.017, n=23, Accuracy: 88.99%\n",
      "Thresh=0.017, n=22, Accuracy: 91.31%\n",
      "Thresh=0.017, n=21, Accuracy: 89.92%\n",
      "Thresh=0.018, n=20, Accuracy: 90.46%\n",
      "Thresh=0.020, n=19, Accuracy: 89.84%\n",
      "Thresh=0.020, n=18, Accuracy: 89.30%\n",
      "Thresh=0.021, n=17, Accuracy: 91.93%\n",
      "Thresh=0.021, n=16, Accuracy: 90.15%\n",
      "Thresh=0.021, n=15, Accuracy: 88.68%\n",
      "Thresh=0.024, n=14, Accuracy: 88.68%\n",
      "Thresh=0.025, n=13, Accuracy: 87.43%\n",
      "Thresh=0.025, n=12, Accuracy: 85.42%\n",
      "Thresh=0.025, n=11, Accuracy: 89.45%\n",
      "Thresh=0.026, n=10, Accuracy: 88.29%\n",
      "Thresh=0.027, n=9, Accuracy: 89.45%\n",
      "Thresh=0.028, n=8, Accuracy: 88.83%\n",
      "Thresh=0.036, n=7, Accuracy: 82.62%\n",
      "Thresh=0.040, n=6, Accuracy: 90.76%\n",
      "Thresh=0.057, n=5, Accuracy: 88.67%\n",
      "Thresh=0.058, n=4, Accuracy: 79.91%\n",
      "Thresh=0.061, n=3, Accuracy: 80.14%\n",
      "Thresh=0.066, n=2, Accuracy: 74.17%\n",
      "Thresh=0.090, n=1, Accuracy: 64.08%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "XGB_Classifier_sfm=XGBClassifier(eta=0.3,\n",
    "                             max_depth=4,\n",
    "                             min_child_weight=1,\n",
    "                             tree_method='approx',\n",
    "                            booster='gbtree'\n",
    "                             )\n",
    "XGB_Classifier_sfm.fit(X_train_resampled_scaled_df, y_train_resampled)\n",
    "\n",
    "thresholds = np.sort(XGB_Classifier_sfm.feature_importances_)\n",
    "\n",
    "best_acc=0\n",
    "for thresh in thresholds:\n",
    "    # select features using threshold\n",
    "    selection = SelectFromModel(XGB_Classifier_sfm, threshold=thresh, prefit=True)\n",
    "    select_X_train = selection.transform(X_train_resampled)\n",
    "    # train model\n",
    "    selection_model = XGBClassifier(eta=0.3,max_depth=4,min_child_weight=1,tree_method='approx',booster='gbtree')\n",
    "    selection_model.fit(select_X_train, y_train_resampled)\n",
    "    # eval model\n",
    "    select_X_test = selection.transform(X_test_df)\n",
    "    predictions = selection_model.predict(select_X_test)\n",
    "    accuracy = balanced_accuracy_score(y_test, predictions)\n",
    "    if accuracy>best_acc:\n",
    "        best_acc=accuracy\n",
    "        best_thresh=thresh\n",
    "    print(\"Thresh=%.3f, n=%d, Accuracy: %.2f%%\" % (thresh, select_X_train.shape[1], accuracy*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "23ece46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold=best_thresh\n",
    "selection = SelectFromModel(XGB_Classifier_sfm, threshold=threshold, prefit=True)\n",
    "select_X_train = selection.transform(X_train_resampled)\n",
    "# train model\n",
    "selection_model = XGBClassifier(eta=0.3,max_depth=4,min_child_weight=1,tree_method='approx',booster='gbtree')\n",
    "selection_model.fit(select_X_train, y_train_resampled)\n",
    "# eval model\n",
    "select_X_test = selection.transform(X_test_df)\n",
    "predictions = selection_model.predict(select_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "deb88fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensionality before feature selection: (696, 56)\n",
      "Dimenionality after feature selection: (696, 56)\n"
     ]
    }
   ],
   "source": [
    "print('Dimensionality before feature selection:',X_train_resampled.shape)\n",
    "print('Dimenionality after feature selection:',select_X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d7ae1306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       161\n",
      "           1       0.89      0.98      0.93        43\n",
      "\n",
      "    accuracy                           0.97       204\n",
      "   macro avg       0.94      0.97      0.96       204\n",
      "weighted avg       0.97      0.97      0.97       204\n",
      "\n",
      "[[156   5]\n",
      " [  1  42]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions, labels=[0,1]))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ef3253",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "480b4d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_predictions(base_1, base_2, voting, X, y, test):\n",
    "    ensemble=VotingClassifier(estimators=[\n",
    "        ('base_1',base_1), ('base_2',base_2)], voting=voting, n_jobs=-1, verbose=True)\n",
    "    ensemble.fit(X,y)\n",
    "    predictions=ensemble.predict(test)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677dc617",
   "metadata": {},
   "source": [
    "#### XGBoost and KNN\n",
    "Soft voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d73d4894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'algorithm': 'ball_tree',\n",
       " 'metric': 'manhattan',\n",
       " 'n_neighbors': 8,\n",
       " 'weights': 'uniform'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "GSparameters_KNN = {\n",
    "    'n_neighbors':[5,7,8,10],\n",
    "    'weights':['uniform','distance'],\n",
    "    'algorithm':['ball_tree','kd_tree','brute'],\n",
    "    'metric': ['minkowski','manhattan']\n",
    "}\n",
    "\n",
    "KNN_GSmodel= KNeighborsClassifier()\n",
    "clf_KNN = GridSearchCV(KNN_GSmodel,\n",
    "                   GSparameters_KNN,\n",
    "                   scoring='balanced_accuracy',\n",
    "                   n_jobs=-1)\n",
    "clf_KNN.fit(X_train_resampled,y_train_resampled)\n",
    "clf_KNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f9febd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "\n",
    "params_knn = {\n",
    "    'n_neighbors': 8,\n",
    "    'weights': 'uniform',\n",
    "    'algorithm':'ball_tree',\n",
    "    'n_jobs':-1,\n",
    "    'metric': 'manhattan'\n",
    "}\n",
    "\n",
    "params_XGB={\n",
    "    'eta':0.3,\n",
    "    'max_depth':4,\n",
    "    'min_child_weight':1,\n",
    "    'tree_method':'approx',\n",
    "    'booster':'gbtree'\n",
    "}\n",
    "\n",
    "KNN_ensemble = KNeighborsClassifier(**params_knn)\n",
    "XGB_ensemble = XGBClassifier(**params_XGB)\n",
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('KNN', KNN_ensemble), ('XGB', XGB_ensemble)], voting='soft', n_jobs=-1, verbose=True)\n",
    "\n",
    "ensemble = ensemble.fit(select_X_train, y_train_resampled)\n",
    "predictions_ensemble=ensemble.predict(select_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3d4fe35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.94      0.97       161\n",
      "           1       0.82      0.98      0.89        43\n",
      "\n",
      "    accuracy                           0.95       204\n",
      "   macro avg       0.91      0.96      0.93       204\n",
      "weighted avg       0.96      0.95      0.95       204\n",
      "\n",
      "[[152   9]\n",
      " [  1  42]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_ensemble, labels=[0,1]))\n",
    "print(confusion_matrix(y_test,predictions_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e093f3",
   "metadata": {},
   "source": [
    "#### XGBoost and Adaboost and Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7c31a419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 1.0, 'n_estimators': 80}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "GSparameters_Ada = {\n",
    "    'n_estimators':[50,80,100,120],\n",
    "    'learning_rate':[1.0,2.0,3.0],\n",
    "}\n",
    "\n",
    "Adaboost_GS= AdaBoostClassifier()\n",
    "clf_Ada = GridSearchCV(Adaboost_GS,GSparameters_Ada,\n",
    "                       refit=True,\n",
    "                       scoring='balanced_accuracy',\n",
    "                       verbose=2,\n",
    "                       n_jobs=-1)\n",
    "clf_Ada.fit(X_train_resampled,y_train_resampled)\n",
    "clf_Ada.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a0aa27ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'class_weight': 'balanced', 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "GSparameters_SVM = {\n",
    "    'C':[0.1,1,10,100,1000],\n",
    "    'gamma':['scale','auto'],\n",
    "    'kernel':['linear','poly','rbf','sigmoid'],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "\n",
    "SVC_GS= SVC()\n",
    "clf_SVC = GridSearchCV(SVC_GS,GSparameters_SVM,\n",
    "                       refit=True,\n",
    "                       scoring='balanced_accuracy',\n",
    "                       verbose=2,\n",
    "                       n_jobs=-1)\n",
    "clf_SVC.fit(X_train_resampled,y_train_resampled)\n",
    "\n",
    "print(clf_SVC.best_params_)\n",
    "print(clf_SVC.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c5cac600",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from catboost import Pool, CatBoostClassifier\n",
    "\n",
    "params_Ada = {\n",
    "    'learning_rate': 1.0, \n",
    "    'n_estimators': 80\n",
    "}\n",
    "\n",
    "\n",
    "base_XGB=XGBClassifier(**params_XGB)\n",
    "base_Ada=AdaBoostClassifier(**params_Ada)\n",
    "base_CatBoost=CatBoostClassifier()\n",
    "\n",
    "ensemble_2 = VotingClassifier(estimators=[\n",
    "     ('XGB', base_XGB), ('Adaboost', base_Ada), ('CatBoost', base_CatBoost)], voting='soft', n_jobs=-1, verbose=True)\n",
    "\n",
    "ensemble_2 = ensemble_2.fit(select_X_train, y_train_resampled)\n",
    "predictions_ensemble=ensemble_2.predict(select_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "11204e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       161\n",
      "           1       0.89      0.98      0.93        43\n",
      "\n",
      "    accuracy                           0.97       204\n",
      "   macro avg       0.94      0.97      0.96       204\n",
      "weighted avg       0.97      0.97      0.97       204\n",
      "\n",
      "[[156   5]\n",
      " [  1  42]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_ensemble, labels=[0,1]))\n",
    "print(confusion_matrix(y_test,predictions_ensemble))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ecd60",
   "metadata": {},
   "source": [
    "#### XGBoost and TabFPN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c98a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "base_tabFPN = TabPFNClassifier(device='cpu', N_ensemble_configurations=32)\n",
    "\n",
    "ensemble_3 = VotingClassifier(estimators=[\n",
    "     ('XGB', base_XGB), ('TabFPN', base_tabFPN)], voting='soft', n_jobs=-1, verbose=True)\n",
    "\n",
    "ensemble_3 = ensemble_3.fit(select_X_train, y_train_resampled)\n",
    "predictions_ensemble=ensemble_3.predict(select_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdabc292",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8849278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bfe3782",
   "metadata": {},
   "source": [
    "TODO: Use the times in metadata like https://www.kaggle.com/code/scipygaurav/icr-improved-tabpfn-xgb-lb-0-11#Loading-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7862805c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "times = metadata.Epsilon.copy()\n",
    "times[metadata.Epsilon != 'Unknown'] = metadata.Epsilon[metadata.Epsilon != 'Unknown'].map(lambda x: datetime.strptime(x,'%m/%d/%Y').toordinal())\n",
    "times[metadata.Epsilon == 'Unknown'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "94b5d888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      737137.0\n",
       "1           NaN\n",
       "2           NaN\n",
       "3           NaN\n",
       "4      737509.0\n",
       "         ...   \n",
       "612    737681.0\n",
       "613    737676.0\n",
       "614    737264.0\n",
       "615    737090.0\n",
       "616         NaN\n",
       "Name: Epsilon, Length: 617, dtype: object"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cd062",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_and_time = pd.concat((select_X_train, times), axis=1)\n",
    "test_predictors = np.array(test_df[predictor_columns])\n",
    "test_pred_and_time = np.concatenate((test_predictors, np.zeros((len(test_predictors), 1)) + \n",
    "                                     train_pred_and_time.Epsilon.max() + 1), axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
